{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this script in Google Colab to process the data and generate new csv files with the additional columns:\n",
    "\n",
    "- hue\n",
    "- saturation\n",
    "- lightness\n",
    "- contrast\n",
    "- sharpness\n",
    "- num_faces\n",
    "\n",
    "Make sure that the original csv files are located in your Google Drive under \"Data Literacy Project/\" (or rename the prefix variable to the correct path).\n",
    "\n",
    "This script will take a while to run, so be patient.\n",
    "\n",
    "The new csv files will be saved in the same directory as the original csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.colab import drive, userdata\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "prefix = '/content/drive/MyDrive/Data Literacy Project/'\n",
    "file_names = [\"education.csv\", \"entertainment.csv\", \"comedy.csv\", \"howto_style.csv\", \"people-and-blogs.csv\", \"gaming.csv\", \"sports.csv\", \"news-and-politics.csv\"]\n",
    "\n",
    "def load_file(file_name):\n",
    "  return pd.read_csv(prefix + file_name)\n",
    "\n",
    "def save_file(df, file_name):\n",
    "  df.to_csv(prefix + file_name)\n",
    "\n",
    "df_arr = [load_file(file_name) for file_name in file_names]\n",
    "print(\"Number of csv files: \", len(df_arr))\n",
    "print(df_arr[0].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "\n",
    "def time_it(func):\n",
    "    \"\"\"\n",
    "    Decorator to print the time taken for a function to execute.\n",
    "    \"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Time taken for {func.__name__}: {end_time - start_time} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def load_single_image(image_path: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes a single image path and returns the image as a Numpy array.\n",
    "    \"\"\"\n",
    "    image_bgr = cv2.imread(image_path)\n",
    "    if image_bgr is None:\n",
    "        raise ValueError(f\"Image at path '{image_path}' could not be loaded.\")\n",
    "    return image_bgr\n",
    "\n",
    "\n",
    "def load_images(image_paths: List[str]) -> List[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Takes a list of image paths and returns the images as a list of Numpy arrays.\n",
    "    \"\"\"\n",
    "    return [load_single_image(image_path) for image_path in image_paths]\n",
    "\n",
    "\n",
    "def download_image(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return Image.open(BytesIO(response.content))\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download image from {url}\")\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_image_features(image_bgr: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Calculates the average hue, saturation, and lightness (HSL) of an image.\n",
    "    Additionally calculates the contrast and sharpness based on the grayscale version.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert BGR to HLS\n",
    "    image_hls = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HLS).astype(np.float32)\n",
    "\n",
    "    # Split into H, L, S channels\n",
    "    H = image_hls[:, :, 0]  # Hue channel (0-179 in OpenCV)\n",
    "    L = image_hls[:, :, 1]  # Lightness channel (0-255)\n",
    "    S = image_hls[:, :, 2]  # Saturation channel (0-255)\n",
    "\n",
    "    # Normalize Hue to [0, 360) degrees\n",
    "    H_degrees = (H * 2) % 360  # OpenCV Hue ranges from 0-179, scaled to 0-358\n",
    "\n",
    "    # Normalize Saturation and Lightness to [0, 1]\n",
    "    S_normalized = S / 255.0\n",
    "    L_normalized = L / 255.0\n",
    "\n",
    "    # Flatten the arrays for processing\n",
    "    H_rad = np.deg2rad(H_degrees.flatten())\n",
    "    S_flat = S_normalized.flatten()\n",
    "    L_flat = L_normalized.flatten()\n",
    "\n",
    "    # Compute mean of sine and cosine of Hue\n",
    "    sin_sum = np.mean(np.sin(H_rad))\n",
    "    cos_sum = np.mean(np.cos(H_rad))\n",
    "\n",
    "    # Calculate average Hue\n",
    "    avg_h_rad = np.arctan2(sin_sum, cos_sum)\n",
    "    if avg_h_rad < 0:\n",
    "        avg_h_rad += 2 * np.pi\n",
    "    avg_hue = np.degrees(avg_h_rad)\n",
    "\n",
    "    # Calculate average Saturation and Lightness\n",
    "    avg_saturation = np.mean(S_flat)\n",
    "    avg_lightness = np.mean(L_flat)\n",
    "\n",
    "    # Calculate image RMS contrast based on grayscale\n",
    "    image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY).astype(np.float32)\n",
    "    rms_contrast = np.std(image_gray / 255.0)\n",
    "\n",
    "    # Calculate image sharpness using the variance of the Laplacian\n",
    "    laplacian_var = cv2.Laplacian(image_gray, cv2.CV_32F).var()\n",
    "\n",
    "    output = {\n",
    "        \"hue\": round(avg_hue, 2),\n",
    "        \"saturation\": round(avg_saturation, 4),\n",
    "        \"lightness\": round(avg_lightness, 4),\n",
    "        \"contrast\": round(rms_contrast, 4),\n",
    "        \"sharpness\": round(laplacian_var, 4)\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install deepface\n",
    "from deepface import DeepFace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "def detect_faces(image_path: str | np.ndarray, detector_backend: str = \"ssd\") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Detect faces in an image and return the bounding boxes of the detected faces.\n",
    "    \"\"\"\n",
    "    resp = DeepFace.extract_faces(img_path=image_path, detector_backend=detector_backend, enforce_detection=False, align=False)\n",
    "    return resp\n",
    "\n",
    "def count_faces(faces: List[Dict[str, Any]]) -> int:\n",
    "    count = int(np.sum([1 for face in faces if face['confidence'] > 0]))\n",
    "    return count\n",
    "\n",
    "def plot_detected_faces(image_path: str | np.ndarray, detector_backend: str = \"ssd\") -> None:\n",
    "    \"\"\"\n",
    "    Detect faces in an image and plot the image with bounding boxes around detected faces.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "        detector_backend (str): Face detector backend to use.\n",
    "            Options: 'opencv', 'retinaface', 'mtcnn', 'ssd', 'dlib', 'mediapipe', 'yolov8', 'centerface'\n",
    "            (default is 'opencv')\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = detect_faces(image_path, detector_backend)\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Plot each detected face\n",
    "    for face in faces:\n",
    "        facial_area = face['facial_area']\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "\n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), w, h,\n",
    "            linewidth=2,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "\n",
    "        # Add the rectangle to the plot\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def plot_image_with_faces(img, faces, ax=None, show=False):\n",
    "    \"\"\"\n",
    "    Plot a single image with detected faces and face count.\n",
    "\n",
    "    Args:\n",
    "        img: Image array in RGB format\n",
    "        faces: List of detected faces\n",
    "        ax: Matplotlib axis to plot on\n",
    "        show: Whether to show the plot immediately\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1)\n",
    "\n",
    "    ax.imshow(img)\n",
    "\n",
    "    # Plot each detected face\n",
    "    for face in faces:\n",
    "        facial_area = face['facial_area']\n",
    "        x, y, w, h = facial_area['x'], facial_area['y'], facial_area['w'], facial_area['h']\n",
    "        rect = patches.Rectangle(\n",
    "            (x, y), w, h,\n",
    "            linewidth=1,\n",
    "            edgecolor='r',\n",
    "            facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    # Add face count text below the image\n",
    "    ax.text(0.5, -0.1, f'Faces: {count_faces(faces)}',\n",
    "            horizontalalignment='center',\n",
    "            transform=ax.transAxes)\n",
    "\n",
    "    ax.axis('off')\n",
    "\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_backend = \"retinaface\"\n",
    "\n",
    "# Process each dataframe and add new columns\n",
    "for i, df in enumerate(df_arr):\n",
    "    # Initialize new columns with None\n",
    "    features = ['hue', 'saturation', 'lightness', 'contrast', 'sharpness', 'num_faces']\n",
    "    for feature in features:\n",
    "        df[feature] = None\n",
    "    \n",
    "    # Process each row\n",
    "    for idx in tqdm(df.index, desc=f\"Processing images in {file_names[i]}\"):\n",
    "        try:\n",
    "            # Load and process image\n",
    "            img_path = df.loc[idx, 'thumbnail-url']\n",
    "            img = np.array(download_image(img_path))\n",
    "            \n",
    "            # Calculate image features\n",
    "            img_features = calculate_image_features(img)\n",
    "            \n",
    "            # Detect faces\n",
    "            faces = detect_faces(img_path, detector_backend=detector_backend)\n",
    "            face_count = count_faces(faces)\n",
    "            \n",
    "            # Update row with new features\n",
    "            df.loc[idx, 'hue'] = img_features['hue']\n",
    "            df.loc[idx, 'saturation'] = img_features['saturation']\n",
    "            df.loc[idx, 'lightness'] = img_features['lightness']\n",
    "            df.loc[idx, 'contrast'] = img_features['contrast']\n",
    "            df.loc[idx, 'sharpness'] = img_features['sharpness']\n",
    "            df.loc[idx, 'num_faces'] = face_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {idx} in {file_names[i]}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Save the updated dataframe\n",
    "    save_file(df, f\"processed_{file_names[i]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
