\documentclass{article}

% if you need to pass options to natbib, use, e.g.,:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2021

% ready for submission
\usepackage[preprint]{neurips_2023}

% to compile a preprint version, e.g.,, for submission to arXiv, add add the
% [preprint] option:
%     \usepackage[preprint]{neurips_2021}

% to compile a camera-ready version, add the [final] option, e.g.,:
%     \usepackage[final]{neurips_2021}

% to avoid loading the natbib package, add option nonatbib:
%    \usepackage[nonatbib]{neurips_2021}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage[colorlinks=true]{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{xcolor}         % colors
\usepackage{graphicx}       % for images
\title{Decoding Eye-Catchiness: Exploring the\\Relationship Between Thumbnail Features\\and Viewer Metrics on YouTube}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{%
  Lean Ting Jin\\
  Matrikelnummer 6956985\\
  \And
  Finn Springorum\\
  Matrikelnummer 6124977\\
  \AND
  Christian Traxler\\
  Matrikelnummer 6969273\\
  \And
  Anna Chechenina\\
  Matrikelnummer 6987499\\
}

\begin{document}

\maketitle

\begin{abstract}
Visually appealing YouTube thumbnails are believed to increase viewership and thus generate more income for creators. In this study, we investigate this hypothesis by analyzing the relationship between features associated with thumbnail eye-catchiness and the view count, based on 80,000 entertainment videos collected with the YouTube Data API \cite{youtubeapi}. We normalized view counts relative to subscriber counts and applied linear regression models to identify potential correlations. Our results suggest that videos with higher view counts tend to have more eye-catching thumbnails. However, thumbnail features were insufficient to explain variations in view counts unaccounted for by subscriber counts of the corresponding channels.
\end{abstract}

\section{Introduction}
YouTube is the second most visited website in the world. In 2024, creators uploaded over 378 million hours of content to YouTube, and were paid more than 50 billion dollars in revenue~\cite{youtube-stats}. For YouTube creators, there is a significant financial incentive to maximize the views of their videos, whose promotion depends on the enigmatic YouTube algorithm. However, it is ultimately the user who decides in a split second whether a video is watched. Thumbnails, the primary visual element presented to users, appear to play a crucial role in influencing user engagement and selection, as suggested by YouTube's official resources \cite{YouTubeThumbnail}.

Quantifying the eye-catchiness of a thumbnail is inherently challenging. However, certain features, such as image color, saturation, and the presence of human faces, likely contribute to visual prominence. As a proxy for eye-catchiness, our study examines six thumbnail-derived features: hue, saturation, lightness, contrast, sharpness, and the number of faces. We hypothesize that more eye-catching thumbnails lead to higher video view counts.

\section{Methods}

\textbf{Data Collection.} We used the YouTube Data API \cite{youtubeapi} to collect video data from eight of YouTube's 15 categories: Comedy, Education, Entertainment, Gaming, How-to \& Style, News \& Politics, People \& Blogs, and Sports. These videos are primarily designed to appear in a user's feed and elicit a response, making them suitable for our thumbnail study.

Due to the limited number of videos that can be retrieved for a given query, the date range from January 1st, 2015 to the time of collection was divided into disjoint intervals, and 500 videos were requested for each interval. To prevent duplicates while respecting the daily API limit, we collected 2,500 videos from a designated category using a distinct singular generic keyword (e.g., most popular video games for the Gaming category), until the collection comprised precisely 10,000 unique videos from said category, yielding a dataset with a total of 80,000 unique videos.

\textbf{Video and Thumbnail Features.} For each video, we collected its thumbnail, view count, and subscriber count. From each thumbnail, we extracted the six features. Hue, saturation, and lightness represent the average values of the thumbnail in the HSL image format \cite{HSL} (as implemented in OpenCV~\cite{opencv_library}), where hue ranges from 0 to 360 degrees, and saturation and lightness are normalized to [0,1]. Contrast is defined as the root mean square contrast, which is the standard deviation of the grayscale image \cite{contrast}. Sharpness is measured as the log variance of the Laplacian of the grayscale image \cite{sharpness}. The number of faces is the number of distinct faces in the thumbnail as predicted by the RetinaFace model implemented in the DeepFace library \cite{serengil2024lightface,serengil2020lightface}.

\textbf{Analysis.} We were interested the the relationship between the view count $N_i$ and the six features derived from the thumbnail $T_i$. However, intuition expects correlation between a video's view count and a channel's subscriber count $S_i$. A linear regression (LR) model (Fig.~\ref{fig:subscriber}) confirms this relationship with a strong positive Pearson correlation ($\rho=0.68$). 
To isolate variations in view count independent of subscriber count, we regressed the log-transformed view count against the log-transformed subscriber count for each category (log: base 10). The log-transformation ensures that the residuals are approximately homoscedastic and normally distributed, as the view and subscriber count distribution appears to be log-normal. We obtained the residuals $R_{i} := \log(N_i) - \hat{\beta}_0^{(\gamma)} - \hat{\beta}_1^{(\gamma)} \log(S_i)$, where $\gamma \in \{1,..., 8\}$ corresponds the category of video $V_i$. We refer to these as "residual log view count" and utilize them, along with the non-normalized "log view count", in the subsequent analysis.

\begin{figure}[h]
  \begin{minipage}[t]{0.67\textwidth}
    \vspace{0pt}  % Removes top spacing
    \includegraphics[width=\textwidth]{figs/subscriber.png}
  \end{minipage}%
  \hspace{0.05\textwidth}%
  \begin{minipage}[t]{0.27\textwidth}
    \vspace{0pt}  % Removes top spacing
    \caption{Linear regression (LR) of the log view count ($\log{(N_i)}$) against the log subscriber count ($\log{(S_i)}$) across the eight video categories, revealing consistent relationships. For the combined dataset, the relationship is given by $\widehat{\log(N_i)} = \hat{\beta}_0 + \hat{\beta}_1 \cdot \log(S_i)$, with 95\% confidence intervals (CIs) for $\beta_0$ as $[3.445, 3.571]$, for $\beta_1$ as $[0.663, 0.673]$, and $R^2 = 0.467$.}
    \label{fig:subscriber}
  \end{minipage}
\end{figure}

Furthermore, the correlation between the six thumbnail features was analyzed. No strong multicollinearity between features was observed, except for a strong positive correlation between lightness and contrast ($\rho=0.79$).
%A random forest regression model with 500 trees and three out of six features considered per split was applied to obtain some non-linear insights about the feature importance.

Moreover, a linear regression model was fitted to each continuous feature (saturation, lightness, contrast, sharpness). Meanwhile, the number of faces and the hue were treated as categorical features, with 95\% confidence intervals (CIs) of the log view count and residual log view count computed for each category. The face count data was categorized into four groups: 0, 1, 2, and 3+ (the last category comprising all videos with at least three detected faces on their thumbnail). The hue was divided into six bins corresponding to a 60-degree range.

Finally, both view counts were fitted against saturation, contrast, sharpness, and the number of faces in a multiple linear regression model. We omitted the lightness feature due to the multicollinearity mentioned above, and the hue feature due to its unique and non-linear characteristics.

\section{Results}
We focus our analysis on the entire dataset with nearly 80,000 valid data points, since we did not observe significant differences between the eight video categories.
%For both the log view count and residual log view count, the feature importance results of the random forest model were similar for the five simple image features hue, saturation, lightness, contrast, and sharpness (around $0.19$), with slight variations between the categories, whereas the number of faces yielded a smaller importance of about $0.05$.

The linear regression models for the continuous features (Fig. \ref{fig:lr}) revealed a positive slope for the log view count against each feature individually, a smaller positive slope for the residual log view count against saturation, and even a negative slope for the relationship between normalized views and lightness, contrast, and sharpness, respectively. The 95\% confidence intervals for the face count and hue (Fig. \ref{fig:faces-and-hue}) also exhibited major differences between the log and residual log view counts. While the log view count intervals for thumbnails with at least one face were higher and did not overlap with the interval for no faces, this trend was absent for the residual log view count. For the hue, however, the confidence intervals for both types of view counts with a mid-range average hue lay clearly above those of the 0-60 and 300-360 degree range.

\begin{figure}[h]


  \centering
  \includegraphics[width=\textwidth]{figs/lr.png}
  \caption{Linear regression results for the log view count (top) and residual log view count (bottom) against saturation, lightness, contrast, and sharpness, respectively, across the entire dataset.}
  \label{fig:lr}
\end{figure}

\begin{figure}[h]
  \begin{minipage}[t]{0.67\textwidth}
    \vspace{0pt}  % Removes top spacing
    \includegraphics[width=\textwidth]{figs/faces-and-hue.png}
  \end{minipage}%
  \hspace{0.1\textwidth}%
  \begin{minipage}[t]{0.27\textwidth}
    \vspace{0pt}  % Removes top spacing
    \caption{95\% CIs of the log view count (top) and residual log view count (bottom) for the different face and hue categories. The hue boxplot colors correspond to the central hue of each bin, and circle sizes are proportional to the respective sample size.}
    \label{fig:faces-and-hue}
  \end{minipage}
\end{figure}

\begin{table}[h]
\centering
\begin{tabular}{lrrrr}
\toprule
& \multicolumn{2}{c}{Non-normalized} & \multicolumn{2}{c}{Normalized} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
Feature & 95\% CI & $p$-value & 95\% CI & $p$-value \\
\midrule
Saturation & [1.482, 1.627] & $<10^{-308}$ & [0.362, 0.470] & $<10^{-308}$ \\

Contrast & [-1.587, -1.236] & $<10^{-308}$ & [-1.043, -0.780] & $<10^{-41}$ \\
Sharpness & [0.637, 0.699] & $<10^{-308}$ & [-0.011, 0.036] & 0.294 \\
Number of faces & [0.012, 0.020] & $<10^{-13}$ & [-0.013, -0.006] & $<10^{-8}$ \\
\bottomrule
\end{tabular}
\vspace{\baselineskip}
\caption{95\% coefficient CI and $p$-value for each feature in the two multiple linear regression models. $R^2 = 0.055$ (log view count) and $R^2 = 0.006$ (residual log view count).}
\label{tab:regression}
\end{table}

For the multiple linear regression model (Tab.~\ref{tab:regression}), we obtained $p$-values negligibly close to zero for the overall model. For the non-normalized view count, all $p$-values for the different features were almost zero, and all coefficients except for the contrast coefficient were positive. For the normalized view count, the $p$-value for sharpness was $0.294$, the others were almost zero as well, and the coefficients were mostly negative or close to zero, except for the saturation coefficient.

\section{Discussion/Limitations}
\textbf{Findings.} The near-zero $p$-values of our multiple linear regression results indicate a significant relationship between multiple features we associate with the eye-catchiness of a thumbnail and the view count of the corresponding video. However, one must distinguish between the non-normalized and the normalized version of the view count. For the former one, we observed positive slopes in the single regression models, and a significant difference between videos with and without faces on their thumbnails. While these observations support our hypothesis, the causality remains unclear, since these findings could also imply that more successful channels produce more eye-catching thumbnails but obtain more views due to other features unrelated to eye-catchiness. Most importantly, the clear correlation with the subscriber count must be addressed. After normalizing the view count, most of our regression plots no longer showed positive relationships. This suggests that the eye-catchiness, as defined by us, is likely insufficient to explain the variations in view count for a fixed number of subscribers. Only the saturation feature coefficients were always positive, which may indicate that saturation is the most important feature to optimize as a YouTube creator. Interestingly, the analysis for the hue was consistent across non-normalized and normalized view counts, indicating that thumbnails with predominantly green and blue colors might yield more views on average compared to reddish ones. Future work could explore supplementary color representations, such as RGB, or alternative metrics for color, such as color quantization~\cite{colorquantization}.
%Notably, applying a simple random forest regression model did not yield meaningful results.
% The random forest model did not provide valuable information either, since the five simple image features were relatively similar in terms of predictive power, only the face count showed a much lower feature importance which might be due to its discrete and thus limited nature. 

\textbf{Other Limitations.} We found linear regression models to be the most plausible for our study, as more complex relationships are highly unlikely. However, these assumptions might not hold, and the linear regression was inaccurate and distorted by outliers, particularly in the sharpness regressions. Moreover, there are some inherent limitations of the YouTube Data API. Firstly, the video categories are somewhat overlapping and vague, being user-defined or automatically generated. Additionally, the API does not grant access to important data, such as the number of impressions, average view duration, or click-through rate for videos, all of which could be important factors to consider. Since this data is not public, future work could collaborate with major channels to analyze their data. Furthermore, despite our dataset being reasonably large, it cannot be fully representative of all YouTube videos, as the video search algorithm favors popular and recent videos.

\textbf{Text Detection.} Initially, we intended to consider the presence of text on the thumbnails as an additional eye-catching feature. However, during the analysis and implementation, we observed poor accuracy of the models, even after attempting to identify the language from the video titles. Consequently, we decided not to include this feature in our study and leave it open for future research.
%Future work could include such analysis by only analyzing videos in languages employing the Roman alphabet to decrease the error rate in the text detection models.

\section{Statement of Contributions}
Chase and Finn set up the main API scripts, performed the correlation and regression analysis, and created the plots. Christian wrote API scripts to collect the subscriber counts for our dataset. Anna implemented and analyzed the text detection methods and models. All members of the group contributed to collecting the dataset and writing the report.
% XX performed the correlation analysis, organized the data and code for the processing of dataset1 and subdataset2, and created the scatter plot. 
% YY created the random forest regression model, performed the data cleaning for the xyz analysis / xyz database, and created the bar charts to display the regression results. 
% ZZ researched and collected the raw data, restructured the pipeline for the data analysis, and proof-read the draft for the final report. 
% AA performed the data cleaning for dataset1, and performed the Ridge and Lasso regularization. 
% All members of the group contributed to writing the report.

\vfill
\pagebreak

\bibliographystyle{unsrt}%Used BibTeX style is unsrt
\bibliography{bibliography}

\end{document}